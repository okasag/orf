document()
check()
library(orf)
# set working directory
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
## load dgp function
source("simulate_data_ORF_function.R")
# general simulation settings
n             <- 10000 # sample size
n_test        <- 1000 # test sample size
# number of discrete values for Y (3,6,9)
Y_n           <- 3
# settings for different DGPs (TRUE/FALSE) - use complicated GDP now
noise             <- TRUE # additional noise variables
highdim           <- FALSE # 1000 noise (zero signal) variables
nonlinear         <- TRUE # nonlinear effects as sin(2X)*beta
multi             <- TRUE # multicollinearity of X
randomcuts        <- FALSE # equal or random cutpoints for Y*
# simulate data
sim_data <- ologit_DGP(Y_n, n, n_test, multi, noise, highdim, nonlinear, randomcuts)
# remove everything
rm(list=setdiff(ls(), c("sim_data")))
X <- as.matrix(sim_data$odata[, -1])
Y <- as.matrix(as.numeric(sim_data$odata[, 1]))
orf_model <- orf(X,Y)
orf_model
summary(orf_model)
summary(orf_model, latex = TRUE)
library(devtools)
document()
check()
library(orf)
# set working directory
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
## load dgp function
source("simulate_data_ORF_function.R")
# general simulation settings
n             <- 10000 # sample size
n_test        <- 1000 # test sample size
# number of discrete values for Y (3,6,9)
Y_n           <- 3
# settings for different DGPs (TRUE/FALSE) - use complicated GDP now
noise             <- TRUE # additional noise variables
highdim           <- FALSE # 1000 noise (zero signal) variables
nonlinear         <- TRUE # nonlinear effects as sin(2X)*beta
multi             <- TRUE # multicollinearity of X
randomcuts        <- FALSE # equal or random cutpoints for Y*
# simulate data
sim_data <- ologit_DGP(Y_n, n, n_test, multi, noise, highdim, nonlinear, randomcuts)
# remove everything
rm(list=setdiff(ls(), c("sim_data")))
X <- as.matrix(sim_data$odata[, -1])
Y <- as.matrix(as.numeric(sim_data$odata[, 1]))
orf_model <- orf(X,Y)
summary(orf_model, latex = TRUE)
summary(orf_model, latex = FALSE)
orf_model
library(devtools)
document()
check()
library(orf)
data(data_cr, envir = .GlobalEnv, package = "mvord")
install.packages("mvord")
data(data_cr, envir = .GlobalEnv, package = "mvord")
View(data_cr)
library(haven)
odata <- read_dta("https://stats.idre.ucla.edu/stat/data/ologit.dta")
View(odata)
data_cr$RATING <- pmax(data_cr$rater1, data_cr$rater2, na.rm = T)
x <- c("LR", "LEV", "PR", "RSIZE", "BETA")
# LR   : LIQUIDITY RATIO
# LEV  : LEVERAGE RATIO
# PR   : PROFITABILITY RATIO
# RSIZE: LOG OF RELATIVE SIZE
# BETA : SYSTEMATIC RISK
y <- "RATING"
df <- data_cr[!is.na(data_cr[, y]), c(x, y)]
table(df[, y]) / length(df[, y])
library(orf)
View(df)
# fit the model
X <- df[, 1:5]
Y <- as.numeric(df[, 6])
Y
orf(X,Y)
kktko <- orf(X,Y)
summary(kktko)
plot(kktko)
forest <- kktko
## save forest inputs
inputs <- forest$forestInfo$inputs
honesty <- inputs$honesty
categories <- forest$forestInfo$categories
honest_data <- forest$forestInfo$honestData
train_data <- forest$forestInfo$trainData
categories
train_data
honest_data
all_data <- all_data[order(as.numeric(row.names(all_data))), ] # sort data as original
probabilities <- forest$forestPredictions # take out honest predictions
all_data <- rbind(honest_data, train_data) # put data together
all_data <- all_data[order(as.numeric(row.names(all_data))), ] # sort data as original
outcomes <- all_data[, 1] # take the observed outcomes
outcomes
## plot realized categories overlayed with predicted category probabilities
# new colnames
colnames(probabilities) <- sapply(seq_along(categories), function(i) paste0("P(Y=", i, ")"))
# cbind together
df_plot <- cbind(outcomes, probabilities)
# subset according to categories
df_plot_cat <- lapply(seq_along(categories), function(i) as.data.frame(subset(df_plot, outcomes == i)))
# take colmeans
df_cat_means <- lapply(df_plot_cat, function(x) t(as.matrix(colMeans(x)[seq_along(categories)+1])))
# add colmeans to df_plot_cat
df_plot_cat <- mapply(function(x,y) cbind(x, y), df_plot_cat, df_cat_means, SIMPLIFY = FALSE)
# reshape data for ggplot
df_plot_prob <- lapply(df_plot_cat, function(x) stack(x[seq_along(categories)+1]))
df_plot_mean <- lapply(df_plot_cat, function(x) stack(x[seq_along(categories)+1+length(categories)]))
# add colnames
df_plot_prob <- lapply(df_plot_prob, function(x) { colnames(x) <- c("Probability", "Category")
return(x)}
)
# add colnames
df_plot_mean <- lapply(df_plot_mean, function(x) { colnames(x) <- c("Probability", "Category")
return(x)}
)
## generate plot objects
# Use semi-transparent fill
plots <- lapply(seq_along(df_plot_prob), function(i) {
ggplot(df_plot_prob[[i]], aes_string(x="Probability", fill="Category")) +
geom_density(alpha=0.4) +
geom_vline(data=df_plot_mean[[i]], aes_string(xintercept="Probability", color="Category"), linetype="dashed") +
ggtitle(paste("Category", i, sep = " ")) +
xlab("Predicted Probability") +
ylab("Probability Mass") +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5))
})
library(ggplot2)
## generate plot objects
# Use semi-transparent fill
plots <- lapply(seq_along(df_plot_prob), function(i) {
ggplot(df_plot_prob[[i]], aes_string(x="Probability", fill="Category")) +
geom_density(alpha=0.4) +
geom_vline(data=df_plot_mean[[i]], aes_string(xintercept="Probability", color="Category"), linetype="dashed") +
ggtitle(paste("Category", i, sep = " ")) +
xlab("Predicted Probability") +
ylab("Probability Mass") +
theme_bw() +
theme(plot.title = element_text(hjust = 0.5))
})
# print plots
do.call("grid.arrange", c(plots, ncol=1))
library(gridExtra)
# print plots
do.call("grid.arrange", c(plots, ncol=1))
kktko <- orf(X,Y, honesty = FALSE)
summary(kktko)
forest <- kktko
## save forest inputs
inputs <- forest$forestInfo$inputs
honesty <- inputs$honesty
categories <- forest$forestInfo$categories
honest_data <- forest$forestInfo$honestData
train_data <- forest$forestInfo$trainData
train_data
honest_data
probabilities <- forest$forestPredictions # take out honest predictions
honest_data
rbind(honest_data, train_data)
all_data <- rbind(honest_data, train_data) # put data together
all_data <- all_data[order(as.numeric(row.names(all_data))), ] # sort data as original
outcomes <- all_data[, 1] # take the observed outcomes
getwd()
library(devtools)
document
document()
check()
library(orf)
odata
# fit the model
X <- odata[, 2:4]
X
# fit the model
X <- as.matrix(odata[, 2:4])
X
Y <- as.numeric(odata[, 1])
Y
odata[, 1]
Y <- as.matrix(odata[, 1])
Y
kktko <- orf(X,Y, honesty = FALSE)
summary(kktko)
plot(kktko)
load_all()
## standard checks for input data
check_X(X)
Y                <- check_Y(Y, X)
Y                <- check_discrete_Y(Y)
all((Y %% 1)
)
all((Y %% 1) != 0)
(any(table(Y)/nrow(Y) < 0.05))
all(sort(unique(Y))
)
sort(unique(Y))
# fit the model
X <- as.matrix(odata[, 2:4])
Y <- as.matrix(odata[, 1])
all((Y %% 1) != 0)
(length(unique(Y)) > 10)
(table(Y)/nrow(Y)
)
sort(unique(Y))
seq_along(unique(Y))
seq_along(unique(Y)))
seq_along(unique(Y))
seq_along(unique(Y))
sort(unique(Y))
sort(unique(Y))[1]
sort(unique(Y))[2]
sort(unique(Y))[3]
if (!all(sort(unique(Y)) == seq_along(unique(Y)))) {
warning(paste(c("The input matrix Y has been recoded to: ", seq_along(unique(Y))), sep = " ", collapse = " "))
# recode Y
for(i in seq_along(unique(Y))) {Y <- replace(Y, Y == sort(unique(Y))[i], seq_along(unique(Y))[i]) }
}
Y
replace(Y, Y == sort(unique(Y))[i], seq_along(unique(Y))[i])
Y <- as.matrix(odata[, 1])
eplace(Y, Y == sort(unique(Y))[i], seq_along(unique(Y))[i])
replace(Y, Y == sort(unique(Y))[i], seq_along(unique(Y))[i])
i <- 2
replace(Y, Y == sort(unique(Y))[i], seq_along(unique(Y))[i])
Y <- as.matrix(odata[, 1])
Y
seq_along(unique(Y))
i <- 3
replace(Y, Y == sort(unique(Y))[i], seq_along(unique(Y))[i])
Y <- replace(Y, Y == sort(unique(Y))[i], seq_along(unique(Y))[i])
Y
i <- 2
replace(Y, Y == sort(unique(Y))[i], seq_along(unique(Y))[i])
Y
Y <- replace(Y, Y == sort(unique(Y))[i], seq_along(unique(Y))[i])
Y
i <- 1
replace(Y, Y == sort(unique(Y))[i], seq_along(unique(Y))[i])
Y <- replace(Y, Y == sort(unique(Y))[i], seq_along(unique(Y))[i])
Y
as.matrix(odata[, 1])
seq_along(unique(Y))
!seq_along(unique(Y))
seq_along(unique(Y))
seq_along(sort(unique(Y))))
seq_along(sort(unique(Y)))
seq_along(sort(unique(Y), decreasing = TRUE))
seq_along(sort(unique(Y), decreasing = TRUE))
sort(unique(Y), decreasing = TRUE)
seq_along(unique(Y))
sort(seq_along(unique(Y)), decreasing = TRUE)
if (!all(sort(unique(Y)) == seq_along(unique(Y)))) {
warning(paste(c("The input matrix Y has been recoded to: ", seq_along(unique(Y))), sep = " ", collapse = " "))
# recode Y (start with the highest value to avoid overwriting)
for(i in sort(seq_along(unique(Y)), decreasing = TRUE)) {Y <- replace(Y, Y == sort(unique(Y))[i], seq_along(unique(Y))[i]) }
}
Y
Y <- as.matrix(odata[, 1])
if (!all(sort(unique(Y)) == seq_along(unique(Y)))) {
warning(paste(c("The input matrix Y has been recoded to: ", seq_along(unique(Y))), sep = " ", collapse = " "))
# recode Y (start with the highest value to avoid overwriting)
for(i in sort(seq_along(unique(Y)), decreasing = TRUE)) {Y <- replace(Y, Y == sort(unique(Y))[i], seq_along(unique(Y))[i]) }
}
Y
document()
check()
replace(Y, Y == sort(unique(Y))[i], seq_along(unique(Y))[i])
Y <- as.matrix(odata[, 1])
Y
replace(Y, Y == sort(unique(Y)), seq_along(unique(Y)))
replace(Y, sort(unique(Y)), seq_along(unique(Y)))
sort(unique(Y))
seq_along(unique(Y))
x <- rep(1:6, 300)
x
(6:1)[x]
Y
(1:3)[Y]
match(1:3,Y)
Y
# fit the model
X <- as.matrix(odata[, 2:4])
Y <- as.matrix(odata[, 1])
Y <- as.matrix(odata[, 1])+1
kktko <- orf(X,Y, honesty = FALSE)
summary(kktko)
plot(kktko)
replace(Y, 1, 10)
replace(Y, c(1,2), c(10,11))
with(Y, replace(Y, Y == 0, 10))
replace(Y, Y == 0, 10))
replace(Y, Y == 0, 10)
Y
Y <- as.matrix(odata[, 1])
Y
replace(Y, Y == 0, 10)
match(Y, 0:2)
Y
Y
match(Y, 0:2)
as.matrix(match(Y, 0:2))
Y[match(Y, 0:2)]
Y
Y <- as.matrix(odata[, 1])
Y
match(Y, 0:2)
transform(Y, Y[match(Y, 0:2)])
transform(Y, Y[match(Y, 1:3)])
transform(Y, Y[match(Y, 0:2)])
match(Y, 0:2)
Y <- as.numeric(Y)
Y
match(Y, 0:2)
Y <- c(1,1,4,6,6,1,6,4,1)
Y
match(Y, c(1,4,6))
match(Y, c(4,1,6))
Y
sort(unique(Y)
)
match(Y, sort(unique(Y)))
Y <- c(0,0,4,6,6,0,6,4,0)
match(Y, sort(unique(Y)))
Y
seq_along(unique(Y))
sort(unique(Y))
getwd()
document()
check()
library(orf)
load_all()
# fit the model
X <- as.matrix(odata[, 2:4])
Y <- as.matrix(odata[, 1])
kktko <- orf(X,Y, honesty = FALSE)
summary(kktko)
plot(kktko)
set.seed(1)
kktko <- orf(X,Y, honesty = FALSE)
summary(kktko)
Y <- as.matrix(odata[, 1]) +1
set.seed(1)
kktko <- orf(X,Y, honesty = FALSE)
summary(kktko)
library(glmnetcr)
install.packages("glmnetcr")
library(glmnetcr)
glmnetcr(X,Y)
ologitlasso <- glmnetcr(X,Y)
summary(ologitlasso)
plot(ologitlasso)
data_cr$RATING <- pmax(data_cr$rater1, data_cr$rater2, na.rm = T)
x <- c("LR", "LEV", "PR", "RSIZE", "BETA")
# LR   : LIQUIDITY RATIO
# LEV  : LEVERAGE RATIO
# PR   : PROFITABILITY RATIO
# RSIZE: LOG OF RELATIVE SIZE
# BETA : SYSTEMATIC RISK
y <- "RATING"
df <- data_cr[!is.na(data_cr[, y]), c(x, y)]
table(df[, y]) / length(df[, y])
library(orf)
# fit the model
X <- df[, 1:5]
Y <- as.numeric(df[, 6])
kktko <- orf(X,Y, honesty = FALSE)
summary(kktko)
plot(kktko)
# fit the model
X <- as.matrix(odata[, 2:4])
Y <- as.matrix(odata[, 1]) +1
set.seed(1)
kktko <- orf(X,Y, honesty = FALSE)
summary(kktko)
plot(kktko)
library(ordinalgmifs)
install.packages("ordinalgmifs")
library(ordinalgmifs)
ordinalgmifs(apply ~ ., data = odata)
kktko <- ordinalgmifs(apply ~ ., data = odata)
summary(kktko)
plot(kktko)
data(eyedisease)
eyedisease
data(hccframe)
hccframe
set.seed(1)
n <- 1000
intercepts <- c(-1, 1)
beta <- c(1, 1, 0, 0, 0)
ncat <- length(intercepts) + 1 # number of response categorie
sp <- length(beta)  # number of covariates
x <- matrix(rnorm(n*p), ncol=p)  # n x p covariate matrix
p <- length(beta)  # number of covariates
x <- matrix(rnorm(n*p), ncol=p)  # n x p covariate matrix
set.seed(1)
n <- 1000
intercepts <- c(-1, 1)
beta <- c(1, 1, 0, 0, 0)
ncat <- length(intercepts) + 1 # number of response categories
p <- length(beta)  # number of covariates
x <- matrix(rnorm(n*p), ncol=p)  # n x p covariate matrix
eta <- c(x %*% beta) + matrix(intercepts, nrow=n, ncol=ncat-1, byrow=TRUE)
invlogit <- function(x) 1 / (1+exp(-x))
cumprob <- t(apply(eta, 1, invlogit))
prob <- cbind(cumprob, 1) - cbind(0, cumprob)
yint <- apply(prob, 1, function(p) sample(1:ncat, size=1, prob=p))
y <- as.factor(yint)
cumprob
prob
yint
y
# Fit parallel cumulative logit model
fit1 <- ordinalNet(x, y, family="cumulative", link="logit",parallelTerms=TRUE, nonparallelTerms=FALSE)
install.packages("ordinalNet")
# Simulate x as independent standard normal# Simulate y|x from a parallel cumulative logit (proportional odds) modelset.seed(1)n <- 50intercepts <- c(-1, 1)beta <- c(1, 1, 0, 0, 0)ncat <- length(intercepts) + 1  # number of response categoriesp <- length(beta)
library(ordinalNet)
set.seed(1)
n <- 1000
intercepts <- c(-1, 1)
beta <- c(1, 1, 0, 0, 0)
ncat <- length(intercepts) + 1 # number of response categories
p <- length(beta)  # number of covariates
x <- matrix(rnorm(n*p), ncol=p)  # n x p covariate matrix
eta <- c(x %*% beta) + matrix(intercepts, nrow=n, ncol=ncat-1, byrow=TRUE)
invlogit <- function(x) 1 / (1+exp(-x))
cumprob <- t(apply(eta, 1, invlogit))
prob <- cbind(cumprob, 1) - cbind(0, cumprob)
yint <- apply(prob, 1, function(p) sample(1:ncat, size=1, prob=p))
y <- as.factor(yint)
# Fit parallel cumulative logit model
fit1 <- ordinalNet(x, y, family="cumulative", link="logit",parallelTerms=TRUE, nonparallelTerms=FALSE)
fit1
plot(fit1)
# fir orf
X <- x
Y <- as.numeric(yint)
fit2 <- orf(X,Y)
summary(fit2)
plot(fit2)
predict(fit2)
jebe <- predict(fit2)
jebe$
summary(fit2)
jebe$forestPredictions
jebe$predictedCategories
jebe$forestVariances
jebe <- predict(fit2)$forestPredictions
predict(fit2)$forestPredictions
jebe1 <- predict(fit1, type = "response")
jebe2 <- predict(fit2)$forestPredictions
mse1 <- mean((prob - jebe1)^2)
mse2 <- mean((prob - jebe2)^2)
load("~/Documents/HSG/ORF/all_functions/sim_data.RData")
# fir orf
odata
margins(fit2)
margins(fit2, eval = "mean")
# fir orf
X <- odata[, -1]
Y <- as.numeric(odata[, 1])
fitorf <- orf(X,Y)
fitnet <- ordinalNet(X, Y, family="cumulative", link="logit",parallelTerms=TRUE, nonparallelTerms=FALSE)
# fir orf
X <- as.matrix(odata[, -1])
Y <- as.numeric(odata[, 1])
fitorf <- orf(X,Y)
fitnet <- ordinalNet(X, Y, family="cumulative", link="logit",parallelTerms=TRUE, nonparallelTerms=FALSE)
# fir orf
X <- as.matrix(odata[, -1])
Y <- as.matrix(odata[, 1])
# fir orf
X <- as.matrix(odata[, -1])
Y <- as.matrix(as.numeric(odata[, 1]))
fitorf <- orf(X,Y)
fitnet <- ordinalNet(X, Y, family="cumulative", link="logit",parallelTerms=TRUE, nonparallelTerms=FALSE)
Y <-odata[, 1])
Y <-odata[, 1]
fitnet <- ordinalNet(X, Y, family="cumulative", link="logit",parallelTerms=TRUE, nonparallelTerms=FALSE)
jebe2 <- predict(fit2)$forestPredictions
jebe1 <- predict(fit1, type = "response")
mse1 <- mean((prob - jebe1)^2)
mse2 <- mean((prob - jebe2)^2)
jebeorf <- predict(fitorf)$forestPredictions
jebenet <- predict(fitnet, type = "response")
mseorf <- mean((prob - jebeorf)^2)
msenet <- mean((prob - jebenet)^2)
install.packages("ordinalLBM")
library(ordinalLBM)
olbm_dat
?olbm_dat
?simu.olbm
olbm_dat
olbmdat <- olbm_dat
data(olbm_dat)
res <- olbm(olbm_dat$Y, Q=3, L=2)
res
plot(res)
plot(fitorf)
90+45
59+43+66
55+45
