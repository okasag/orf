setwd("/home/okasag/Documents/HSG/ORF/real_data_app")
source("~/Documents/HSG/ORF/real_data_app/marginal_effects/output_ologit.R")
### 2. MAMMOGRAPHY DATA
load("~/Documents/HSG/ORF/data/mammography_dataset_rdata.Rdata")
# prepare data
dataset$SYMPT <- as.numeric(dataset$SYMPT)
dataset$PB <- as.numeric(dataset$PB)
dataset$HIST <- as.numeric(dataset$HIST)
dataset$BSE <- as.numeric(dataset$BSE)
dataset$DECT <- as.numeric(dataset$DECT)
dataset$y <- as.numeric(dataset$y)
# matrices
X <- as.matrix(dataset[, 1:ncol(dataset)-1])
Y <- as.matrix(dataset[, ncol(dataset)])
# prepare parameters
ntree <- 10000
# prepare parameters
ntree <- 1000
mtry <- ceiling(sqrt(ncol(X)))
nmin <- 5
honesty <- TRUE
inference <- FALSE
margins <- FALSE
# estimate orf in first place
set.seed(311992) # put your birthday here
orf_model <- orf(X,Y,ntree,mtry,nmin,honesty,inference,margins)
orf_model$forestInfo$inputs$inference <- TRUE
orf_atmean_me <- margins(orf_model, eval = "atmean", NULL)
orf_atmean_me
orf_mean_me <- margins(orf_model, eval = "mean", NULL)
orf_mean_me
### 3. NHANES DATA
load("~/Documents/HSG/ORF/data/nhanes_dataset_rdata.Rdata")
### 4. VLBW DATA
load("~/Documents/HSG/ORF/data/vlbw_dataset_rdata.Rdata")
### 5. SUPPORTSTUDY DATA
load("~/Documents/HSG/ORF/data/supportstudy_dataset_rdata.Rdata")
# prepare data
dataset$sex <- as.numeric(dataset$sex)
dataset$dzgroup <- as.numeric(dataset$dzgroup)
dataset$race <- as.numeric(dataset$race)
dataset$y <- as.numeric(dataset$y)
# all data
dataset <- as.data.frame(apply(dataset, 2, as.numeric))
# matrices
X <- as.matrix(dataset[, 1:ncol(dataset)-1])
Y <- as.matrix(dataset[, ncol(dataset)])
# prepare parameters
ntree <- 1000
mtry <- ceiling(sqrt(ncol(X)))
nmin <- 5
honesty <- TRUE
inference <- FALSE
margins <- FALSE
# estimate orf in first place
set.seed(311992) # put your birthday here
orf_model <- orf(X,Y,ntree,mtry,nmin,honesty,inference,margins)
orf_model$forestInfo$inputs$inference <- TRUE
orf_atmean_me <- margins(orf_model, eval = "atmean", NULL)
orf_atmean_me
orf_mean_me <- margins(orf_model, eval = "mean", NULL)
orf_mean_me
# ologit
ologit <- polr(as.ordered(y) ~ . - charges, data = dataset, Hess = TRUE) # without charges
# marginal effects for ologit at mean
me_ologit <-ocME(ologit, rev.dum = TRUE, digits = 6)
# save output
out <- capture.output(ologit_output(me_ologit))
me_ologit
ologit_output(me_ologit)
orf_mean_me
library(orf)
# get some example data and parameters
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
load("sim_data.RData") # load generated data from ologit
X <- as.matrix(odata[, 2:16])
X_test <- as.matrix(odata_test[, 2:16])
Y <- as.matrix(odata[, 1])
ntree <- 1000
mtry <- 5
nmin <- 5
honesty <- FALSE
inference <- FALSE
margins <- FALSE
honesty <- T
margins <- T
inference <- T
kktko <- orf(X,Y,ntree,mtry,nmin,honesty,inference,margins)
kktko_mean <- marginskktko, "mean", NULL)
kktko_mean <- margins(kktko, "mean", NULL)
kktko_atmean <- margins(kktko, "atmean", NULL)
kktko_atmean
kktko_mean
# load orf
library(orf)
# estimate with polr
library(MASS)
library(erer)
# set wd
setwd("/home/okasag/Documents/HSG/ORF/real_data_app")
source("~/Documents/HSG/ORF/real_data_app/marginal_effects/output_ologit.R")
# get da
### 5. SUPPORTSTUDY DATA
load("~/Documents/HSG/ORF/data/supportstudy_dataset_rdata.Rdata")
# prepare data
dataset$sex <- as.numeric(dataset$sex)
dataset$dzgroup <- as.numeric(dataset$dzgroup)
dataset$race <- as.numeric(dataset$race)
dataset$y <- as.numeric(dataset$y)
# all data
dataset <- as.data.frame(apply(dataset, 2, as.numeric))
# matrices
X <- as.matrix(dataset[, 1:ncol(dataset)-1])
Y <- as.matrix(dataset[, ncol(dataset)])
# prepare parameters
ntree <- 1000
mtry <- ceiling(sqrt(ncol(X)))
nmin <- 5
honesty <- TRUE
inference <- FALSE
margins <- FALSE
View(X)
X <- X[,-6]
View(X)
# estimate orf in first place
set.seed(311992) # put your birthday here
orf_model <- orf(X,Y,ntree,mtry,nmin,honesty,inference,margins)
orf_model$forestInfo$inputs$inference <- TRUE
orf_atmean_me <- margins(orf_model, eval = "atmean", NULL)
orf_mean_me <- margins(orf_model, eval = "mean", NULL)
orf_atmean_me
orf_mean_me
# ologit
ologit <- polr(as.ordered(y) ~ . - charges, data = dataset, Hess = TRUE) # without charges
# marginal effects for ologit at mean
me_ologit <-ocME(ologit, rev.dum = TRUE, digits = 6)
ologit_output(me_ologit)
devtools::load_all()
forest <- orf_model
eval <- "mean"
newdata <- NULL
### decide if prediction or in sample marginal effects should be evaluated
if (is.null(newdata)) {
# if no newdata supplied, estimate in sample marginal effects
if (forest$forestInfo$inputs$honesty == FALSE) {
data <- forest$forestInfo$trainData # take in-sample data
} else if (forest$forestInfo$inputs$honesty == TRUE) {
data <- forest$forestInfo$honestData
}
} else {
# check if newdata is compatible with train data
if (ncol(newdata) != ncol(forest$forestInfo$trainData)) {
stop("newdata is not compatible with training data. Programme terminated.")
} else {
data = newdata
}
}
### data preparation and checks
# get number of observations
n_data <- as.numeric(nrow(data))
# get categories
categories <- forest$forestInfo$categories
# get X as matrix
X <- as.matrix(data[, -1])
# get Y as matrix
Y <- as.matrix(data[, 1])
# create indicator variables (outcomes)
Y_ind <- lapply(categories[1:length(categories)-1], function(x) ifelse((Y <= x), 1, 0))
# create datasets with indicator outcomes
data_ind <- lapply(Y_ind, function(x) as.data.frame(cbind(as.matrix(unlist(x)), X)))
### marginal effects preparation
# share of SD to be used
h_std <- 0.1
# check if X is continuous or dummy or categorical
X_type <- apply(X, 2, function(x) length(unique(x)))
# now determine the type of X
X_continuous <- which(X_type > 10) # define IDs of continuous Xs
X_dummy <- which(X_type == 2) # define IDs of dummies
X_categorical <- which(X_type > 2 & X_type <= 10)
# additional check for constant variables which are nonsensical
if (any(X_type == 1) | any(X_type == 0)) {
stop("Some of the covariates are constant. This is non-sensical for evaluation of marginal effects. Programme terminated.")
}
### check the evaluation point
if (eval == "atmean") {
# variable of interest: X_1 to X_last, ME at mean
X_mean <- lapply(1:ncol(X), function(x) t(as.matrix(colMeans(X)))) # set all Xs to their mean values (so many times as we have Xs)
} else if (eval == "atmedian") {
# variable of interest: X_1 to X_last, ME at median
X_mean <- lapply(1:ncol(X), function(x) t(as.matrix(apply(X, 2, median)))) # set all Xs to their median values (so many times as we have Xs)
} else if (eval == "mean") {
# # variable of interest: X_1 to X_last, mean ME
X_mean <- lapply(1:ncol(X), function(x) X) # set all Xs to their exact values (so many times as we have Xs)
} else {
stop("Incorrect evaluation point. Programme terminated.")
}
X_mean
### get data needed for evaluation of ME
# get number of evaluation points
X_rows <- nrow(X_mean[[1]])
# get number of Xs
X_cols <- ncol(X_mean[[1]])
# get SD of Xs
X_sd <- apply(X, 2, sd)
X_sd
# create X_up (X_mean + 0.1 * X_sd)
X_up <- X_mean[[1]] + h_std*X_sd
# create X_down (X_mean - 0.1 * X_sd)
X_down <- X_mean[[1]] - h_std*X_sd
X_up
X_down
## now check for the support of X
# check X_max
X_max <- apply(X, 2, max)
# check X_min
X_min <- apply(X, 2, min)
X_max
X_min
X_continuous
X_dummy
X_categorical
X_up < X_max
(X_up < X_max) * X_up
(X_up >= X_max)
# check if X_up is within the range X_min and X_max
X_up <- (X_up < X_max) * X_up + (X_up >= X_max) * X_max
X_up
# create X_up (X_mean + 0.1 * X_sd)
X_up <- X_mean[[1]] + h_std*X_sd
X_up
# check if X_up is within the range X_min and X_max
X_up <- (X_up < X_max) * X_up + (X_up >= X_max) * X_max
X_up
X_max
(X_up >= X_max)
# create X_up (X_mean + 0.1 * X_sd)
X_up <- X_mean[[1]] + h_std*X_sd
X_up >= X_max
(X_up >= X_max) * X_max
# create X_up (X_mean + 0.1 * X_sd)
X_up <- X_mean[[1]] + h_std*X_sd
X_up
apply(X_up, 2, ((X_up < X_max) * X_up + (X_up >= X_max) * X_max))
apply(X_up, 2, function(x) ((x < X_max) * x + (x >= X_max) * X_max))
warnings()
apply(X_up, 2, function(x) ((x < X_max) * x + (x >= X_max) * X_max))
apply(X_up, 2, function(x) ((x < X_max) * x)
)
(X_up < X_max
)
(X_up < X_max) * X_up
(X_up < X_max) * X_up
(X_up >= X_max)
(X_up >= X_max) * X_max
X_max
X_up
X_max
apply(X, 2, max)
nrow(X_up)
ncol(X_up)
X_sd
+ h_std*X_sd
X_mean[[1]]
h_std*X_sd
X_up
X_max
matrix(apply(X, 2, max), nrow = nrow(X_up), ncol = ncol(X_up))
(apply(X, 2, max)
)
(apply(X, 2, max))
rep((apply(X, 2, max)), nrow(X_up))
matrix(rep((apply(X, 2, max)), nrow(X_up)), nrow = nrow(X_up), ncol = ncol(X_up))
X_up
X_max
X_max[rep(1:nrow(X_max), 2), ]
rep.row<-function(x,n){
matrix(rep(x,each=n),nrow=n)
}
rep.col<-function(x,n){
matrix(rep(x,each=n), ncol=n, byrow=TRUE)
}
rep.row(X_max,2)
#' repeat rows of a matrix
#'
#' function for replicating rows of a matrix n number of times
#'
#' @param matrix matrix which rows should be replicated
#' @param n number of times to repeat
#'
rep_row<-function(matrix, n){
# thanks to: https://www.r-bloggers.com/a-quick-way-to-do-row-repeat-and-col-repeat-rep-row-rep-col/
matrix(rep(x, each = n), nrow = n)
}
nrow(X_up)
rep_row(apply(X, 2, max), n = nrow(X_up))
apply(X, 2, max)
rep_row(apply(X, 2, max), n = nrow(X_up))
#' repeat rows of a matrix
#'
#' function for replicating rows of a matrix n number of times
#'
#' @param matrix matrix which rows should be replicated
#' @param n number of times to repeat
#'
rep_row<-function(matrix, n){
# thanks to: https://www.r-bloggers.com/a-quick-way-to-do-row-repeat-and-col-repeat-rep-row-rep-col/
matrix(rep(matrix, each = n), nrow = n)
}
rep_row(apply(X, 2, max), n = nrow(X_up))
rep(matrix, each = n)
rep(X_max, each = 2)
matrix(rep(X_max, each = 2), nrow = 2)
rep_row(apply(X, 2, max), n = nrow(X_up))
#' repeat rows of a matrix
#'
#' function for replicating rows of a matrix n number of times
#'
#' @param matrix matrix which rows should be replicated
#' @param n number of times to repeat
#'
rep_row<-function(matrix, n){
# thanks to: https://www.r-bloggers.com/a-quick-way-to-do-row-repeat-and-col-repeat-rep-row-rep-col/
matrix(rep(matrix, each = n), nrow = n)
}
rep_row(apply(X, 2, max), n = nrow(X_up))
## now check for the support of X
# check X_max
X_max <- rep_row(apply(X, 2, max), n = nrow(X_up))
## now check for the support of X
# check X_max
X_max <- rep_row(apply(X, 2, max), n = nrow(X_up))
# check X_min
X_min <- rep_row(apply(X, 2, min), n = nrow(X_down))
X_up
X_max
(X_up < X_max)
(X_up < X_max) * X_up
(X_up >= X_max)
(X_up >= X_max) * X_max
(X_up < X_max) * X_up + (X_up >= X_max) * X_max
(X_up > X_min) * X_up + (X_up <= X_min) * (X_min + h_std * X_sd)
(X_down > X_min) * X_down + (X_down <= X_min) * X_min
(X_down < X_max) * X_down + (X_down >= X_max) * (X_max - h_std * X_sd)
X_min
h_std * X_sd
X_rows
X_min
h_std * X_sd
(X_min + h_std * X_sd)
apply(X, 2, sd)
# get SD of Xs
X_sd <- rep_row(apply(X, 2, sd), n = X_rows)
X_sd
# create X_up (X_mean + 0.1 * X_sd)
X_up <- X_mean[[1]] + h_std*X_sd
# create X_down (X_mean - 0.1 * X_sd)
X_down <- X_mean[[1]] - h_std*X_sd
X_up
h_std*X_sd
X_sd
h_std*X_sd
X_mean[[1]]
# get SD of Xs
X_sd <- rep_row(apply(X, 2, sd), n = X_rows)
# create X_up (X_mean + 0.1 * X_sd)
X_up <- X_mean[[1]] + h_std*X_sd
# create X_down (X_mean - 0.1 * X_sd)
X_down <- X_mean[[1]] - h_std*X_sd
X_down
## now check for the support of X
# check X_max
X_max <- rep_row(apply(X, 2, max), n = X_rows)
# check X_min
X_min <- rep_row(apply(X, 2, min), n = X_rows)
X_max
X_min
(X_up < X_max)
(X_up < X_max) * X_up
(X_up >= X_max)
(X_up >= X_max) * X_max
# check if X_up is within the range X_min and X_max
X_up <- (X_up < X_max) * X_up + (X_up >= X_max) * X_max
X_up
# check if X_up is within the range X_min and X_max
X_up <- (X_up < X_max) * X_up + (X_up >= X_max) * X_max
(X_up > X_min)
(X_up > X_min) * X_up
(X_up <= X_min)
h_std * X_sd
(X_min + h_std * X_sd)
X_up <- (X_up > X_min) * X_up + (X_up <= X_min) * (X_min + h_std * X_sd)
# check if X_down is within the range X_min and X_max
X_down <- (X_down > X_min) * X_down + (X_down <= X_min) * X_min
X_down <- (X_down < X_max) * X_down + (X_down >= X_max) * (X_max - h_std * X_sd)
X_down
h_std * X_sd
X_up == X_down
# check if X_up and X_down are same
if (X_up == X_down) {
# adjust to higher share of SD
X_up   <- (X_up > X_down) * X_up   + (X_up == X_down) * (X_up   + 0.5 * h_std * X_sd)
X_down <- (X_up > X_down) * X_down + (X_up == X_down) * (X_down - 0.5 * h_std * X_sd)
# check the min max range again
X_up <- (X_up < X_max) * X_up + (X_up >= X_max) * X_max
X_down <- (X_down > X_min) * X_down + (X_down <= X_min) * X_min
}
any(X_up == X_down)
(X_up > X_down)
(X_up == X_down)
(X_up   + 0.5 * h_std * X_sd)
# check if X_up and X_down are same
if (any(X_up == X_down)) {
# adjust to higher share of SD
X_up   <- (X_up > X_down) * X_up   + (X_up == X_down) * (X_up   + 0.5 * h_std * X_sd)
X_down <- (X_up > X_down) * X_down + (X_up == X_down) * (X_down - 0.5 * h_std * X_sd)
# check the min max range again
X_up <- (X_up < X_max) * X_up + (X_up >= X_max) * X_max
X_down <- (X_down > X_min) * X_down + (X_down <= X_min) * X_min
}
eval = "atmean"
### check the evaluation point
if (eval == "atmean") {
# variable of interest: X_1 to X_last, ME at mean
X_mean <- lapply(1:ncol(X), function(x) t(as.matrix(colMeans(X)))) # set all Xs to their mean values (so many times as we have Xs)
} else if (eval == "atmedian") {
# variable of interest: X_1 to X_last, ME at median
X_mean <- lapply(1:ncol(X), function(x) t(as.matrix(apply(X, 2, median)))) # set all Xs to their median values (so many times as we have Xs)
} else if (eval == "mean") {
# # variable of interest: X_1 to X_last, mean ME
X_mean <- lapply(1:ncol(X), function(x) X) # set all Xs to their exact values (so many times as we have Xs)
} else {
stop("Incorrect evaluation point. Programme terminated.")
}
### get data needed for evaluation of ME
# get number of evaluation points
X_rows <- nrow(X_mean[[1]])
# get number of Xs
X_cols <- ncol(X_mean[[1]])
apply(X, 2, sd)
# get SD of Xs
X_sd <- rep_row(apply(X, 2, sd), n = X_rows)
X_sd
# create X_up (X_mean + 0.1 * X_sd)
X_up <- X_mean[[1]] + h_std*X_sd
# create X_down (X_mean - 0.1 * X_sd)
X_down <- X_mean[[1]] - h_std*X_sd
X_up
X_down
rep_row(apply(X, 2, max), n = X_rows)
## now check for the support of X
# check X_max
X_max <- rep_row(apply(X, 2, max), n = X_rows)
# check X_min
X_min <- rep_row(apply(X, 2, min), n = X_rows)
X_min
# check if X_up is within the range X_min and X_max
X_up <- (X_up < X_max) * X_up + (X_up >= X_max) * X_max
X_up <- (X_up > X_min) * X_up + (X_up <= X_min) * (X_min + h_std * X_sd)
(X_up < X_max)
(X_up < X_max) * X_up
(X_up >= X_max)
(X_up >= X_max) * X_max
# check if X_up is within the range X_min and X_max
X_up <- (X_up < X_max) * X_up + (X_up >= X_max) * X_max
X_up <- (X_up > X_min) * X_up + (X_up <= X_min) * (X_min + h_std * X_sd)
# check if X_down is within the range X_min and X_max
X_down <- (X_down > X_min) * X_down + (X_down <= X_min) * X_min
X_down <- (X_down < X_max) * X_down + (X_down >= X_max) * (X_max - h_std * X_sd)
X_up == X_down
any(X_up == X_down)
X_up > X_down)
(X_up > X_down)
(X_up == X_down)
(X_up   + 0.5 * h_std * X_sd)
# check if X_up and X_down are same
if (any(X_up == X_down)) {
# adjust to higher share of SD
X_up   <- (X_up > X_down) * X_up   + (X_up == X_down) * (X_up   + 0.5 * h_std * X_sd)
X_down <- (X_up > X_down) * X_down + (X_up == X_down) * (X_down - 0.5 * h_std * X_sd)
# check the min max range again
X_up   <- (X_up < X_max) * X_up + (X_up >= X_max) * X_max
X_down <- (X_down > X_min) * X_down + (X_down <= X_min) * X_min
}
devtools::document()
devtools::check()
library(orf)
load("~/Documents/HSG/ORF/all_functions/sim_data.RData")
X <- as.matrix(odata[, 2:16])
X_test <- as.matrix(odata_test[, 2:16])
Y <- as.matrix(odata[, 1])
ntree <- 1000
mtry <- 5
nmin <- 5
honesty <- FALSE
inference <- FALSE
margins <- FALSE
honesty <- TRUE
# prepare parameters
ntree <- 1000
mtry <- ceiling(sqrt(ncol(X)))
nmin <- 5
honesty <- TRUE
inference <- FALSE
margins <- FALSE
# estimate orf in first place
set.seed(311992) # put your birthday here
orf_model <- orf(X,Y,ntree,mtry,nmin,honesty,inference,margins)
orf_model$forestInfo$inputs$inference <- TRUE
orf_atmean_me <- margins(orf_model, eval = "atmean", NULL)
orf_atmean_me
orf_mean_me <- margins(orf_model, eval = "mean", NULL)
orf_mean_me
