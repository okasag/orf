dat <- as.data.frame(cbind(Y, X)) # dataframe
colnames(dat) <- c(Y_name, X_name) # column names
n <- nrow(dat) # number of observations
# -----------------------------------------
honest_split <- function(data) {
# get number of observations in total
n <- nrow(data)
# needed inputs for the function: data - dataframe which should be split into 50:50 sets
ind <- sample(c(rep(0, n/2), rep(1, n/2))) # randomize indicators
honesty_i <- which(ind == 1) # indicator for whch observations go into train and honest set
train <- data[-honesty_i, ] # separate training set
#rownames(train) <- seq(1:nrow(train)) # set rownames
honest <- data[honesty_i, ] # separate honest set
#rownames(honest) <- seq(1:nrow(honest)) # set rownames
# put it into output
output <- list(train, honest)
names(output) <- c("trainData", "honestData")
# return output
return(output)
}
# devide into 50:50 honesty sets
split_data <- honest_split(dat)
train_data <- split_data$trainData # take out training data
honest_data <- split_data$honestData # take out honest data
# built the forest structure using training set, i.e. place splits
forest         <- ranger(dependent.variable.name = paste(Y_name), data = train_data,
num.trees = ntree, mtry = mtry, replace = FALSE, sample.fraction = 0.5,
importance = "none")
detach("package:ranger", unload=TRUE)
# compute honest predictions
honest_pred <- get_honest(forest, honest_data, train_data)
honest_pred
save.image("~/Documents/HSG/ORF/all_functions/test_data.RData")
library("orf", lib.loc="~/R/x86_64-pc-linux-gnu-library/3.5")
?`orf-package`
load("~/Documents/HSG/ORF/all_functions/test_data.RData")
forest
honest_data
train_data
# compute honest predictions
honest_pred <- get_honest(forest, honest_data, train_data)
honest_pred
rm(honest_pred)
# compute honest predictions
honest_pred <- get_honest(forest, honest_data, train_data)
honest_pred
rm(honest_pred)
honest_pred
# compute honest predictions
honest_pred <- get_honest(forest, honest_data, train_data)
honest_pred
library(devtools)
devtools::document()
devtools::check()
library(orf)
library(orf)
check()
devtools::check()
library(devtools)
document()
check()
document()
check()
document()
check()
document()
check()
library(orf)
# set.seed(311992)
# load libraries
library(ranger)
library(foreach)
# load and prepare data
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# generate data
n <- 1000
betas <- seq(0.1, 1, length.out = 10)
X <- matrix(rnorm(n*10,0,1), ncol = 10)
Y <- inv.logit(X%*%betas)
data <- as.data.frame(cbind(Y, X))
colnames(data) <- c("Y","X1","X2","X3","X4","X5","X6","X7","X8","X9","X10")
X <- matrix(rnorm(n*10,0,1), ncol = 10)
Y <- (X%*%betas)
data <- as.data.frame(cbind(Y, X))
colnames(data) <- c("Y","X1","X2","X3","X4","X5","X6","X7","X8","X9","X10")
# devide into 50/50 honesty sets
ind <- sample(c(rep(0,n/2), rep(1,n/2)))
honesty_i <- which(ind == 1)
train <- data[-honesty_i, ]
rownames(train) <- seq(1:nrow(train))
honest <- data[honesty_i, ]
rownames(honest) <- seq(1:nrow(honest))
# estimate forest on training sample, i.e. honesty_1
forest         <- ranger(Y ~ . , data = train, num.trees = 1000, min.node.size = 5)
data <- honest
# first get terminal nodes, i.e get terminal nodes for each obs and each tree
# run your (new) data through the forest structure and look where your observations end up
leaf_IDs <- predict(forest, data, type = "terminalNodes")$predictions
# put leaf_IDs into a list (one element for one tree)
leaf_IDs <- lapply(seq_along(leaf_IDs[1,]), function(i) leaf_IDs[,i])
leaf_IDs
# estimate forest on training sample, i.e. honesty_1
forest         <- ranger(Y ~ . , data = train, num.trees = 100, min.node.size = 50)
data <- honest
# first get terminal nodes, i.e get terminal nodes for each obs and each tree
# run your (new) data through the forest structure and look where your observations end up
leaf_IDs <- predict(forest, data, type = "terminalNodes")$predictions
# put leaf_IDs into a list (one element for one tree)
leaf_IDs <- lapply(seq_along(leaf_IDs[1,]), function(i) leaf_IDs[,i])
leaf_IDs
# first get terminal nodes, i.e get terminal nodes for each obs and each tree
# run your (new) data through the forest structure and look where your observations end up
leaf_IDs <- predict(forest, data, type = "terminalNodes")$predictions
leaf_IDs
# put leaf_IDs into a list (one element for one tree)
leaf_IDs <- lapply(seq_along(leaf_IDs[1,]), function(i) leaf_IDs[,i])
### formula for single tree: 1(Xi in L(x))/abs(L(x)) - normalized by the size of the leaf
## pre-requisites: leaf size and leaf ID
# get the leaf size as counts of observations in leaves
leaf_size <- lapply(leaf_IDs, function(x) ave(x, x, FUN=length))
leaf_size
# initialize list for storage
forest_weights <- vector("list", length = length(leaf_IDs)) # empty list
# initialize tree weight matrix (n x n)
tree_weights <- vector("list", length = length(leaf_IDs[[1]])) # empty list
forest_weights
tree_weights
# go through each observation and compute the tree-induced weight
tree_weights[[1]] <- foreach(i=seq_along(x)) %do% {
(leaf_IDs[[1]][i]==leaf_IDs[[1]])/leaf_size[[1]]
}
# go through each observation and compute the tree-induced weight
tree_weights[[1]] <- foreach(i=seq_along(leaf_IDs[[1]])) %do% {
(leaf_IDs[[1]][i]==leaf_IDs[[1]])/leaf_size[[1]]
}
tree_weights
leaf_IDs[[1]][1]==leaf_IDs[[1]]
leaf_size[[1]]
# estimate forest on training sample, i.e. honesty_1
forest         <- ranger(Y ~ . , data = train, num.trees = 100, min.node.size = 50)
data <- honest
get_forest_weights <- function(forest, data) {
# require ranger
library(ranger)
# first get terminal nodes, i.e get terminal nodes for each obs and each tree
# run your (new) data through the forest structure and look where your observations end up
leaf_IDs <- predict(forest, data, type = "terminalNodes")$predictions
# put leaf_IDs into a list (one element for one tree)
leaf_IDs <- lapply(seq_along(leaf_IDs[1,]), function(i) leaf_IDs[,i])
### formula for single tree: 1(Xi in L(x))/abs(L(x)) - normalized by the size of the leaf
## pre-requisites: leaf size and leaf ID
# get the leaf size as counts of observations in leaves
leaf_size <- lapply(leaf_IDs, function(x) ave(x, x, FUN=length))
# initialize list for storage
forest_weights <- vector("list", length = length(leaf_IDs)) # empty list
# initialize tree weight matrix (n x n)
tree_weights <- vector("list", length = length(leaf_IDs[[1]])) # empty list
# check each observation
system.time(
forest_weights <- mapply(function(x,y) {
# go through each observation and compute the tree-induced weight
tree_weights <- foreach(i=seq_along(x)) %do% {
(x[i]==x)/y
}
# stack tree weights into a matrix
sapply(tree_weights, function(x) as.matrix(x))
},
leaf_IDs, leaf_size, SIMPLIFY=FALSE)
)
# ALTERNATIVE WEIGHT FUNCTION BASED ON FOREACG #
#system.time(
# foreach(j=seq_along(forest_weights)) %do% {
#  # go through each observation and compute the tree-induced weight
# tree_weights <- foreach(i=seq_along(tree_weights)) %do% {
#  (leaf_IDs[[j]][i]==leaf_IDs[[j]])/leaf_size[[j]]
#}
# put into forest weights
#  forest_weights[[j]] <- sapply(tree_weights, function(x) as.matrix(x))
#}
#)
# now average over the bootstraps, i.e. over trees to get final weights
forest_weights_final <- Reduce("+", forest_weights) / length(forest_weights)
## return forest weight final matrix
return(forest_weights_final)
}
tree_weights[[1]]
sapply(tree_weights, function(x) as.matrix(x))
sapply(tree_weights, function(x) as.matrix(x))
tree_weights
# initialize list for storage
forest_weights <- vector("list", length = length(leaf_IDs)) # empty list
# initialize tree weight matrix (n x n)
tree_weights <- vector("list", length = length(leaf_IDs[[1]])) # empty list
# check each observation
system.time(
forest_weights <- mapply(function(x,y) {
# go through each observation and compute the tree-induced weight
tree_weights <- foreach(i=seq_along(x)) %do% {
(x[i]==x)/y
}
# stack tree weights into a matrix
sapply(tree_weights, function(x) as.matrix(x))
},
leaf_IDs, leaf_size, SIMPLIFY=FALSE)
)
# first get terminal nodes, i.e get terminal nodes for each obs and each tree
# run your (new) data through the forest structure and look where your observations end up
leaf_IDs <- predict(forest, data, type = "terminalNodes")$predictions
# put leaf_IDs into a list (one element for one tree)
leaf_IDs <- lapply(seq_along(leaf_IDs[1,]), function(i) leaf_IDs[,i])
### formula for single tree: 1(Xi in L(x))/abs(L(x)) - normalized by the size of the leaf
## pre-requisites: leaf size and leaf ID
# get the leaf size as counts of observations in leaves
leaf_size <- lapply(leaf_IDs, function(x) ave(x, x, FUN=length))
# initialize list for storage
forest_weights <- vector("list", length = length(leaf_IDs)) # empty list
# initialize tree weight matrix (n x n)
tree_weights <- vector("list", length = length(leaf_IDs[[1]])) # empty list
# check each observation
system.time(
forest_weights <- mapply(function(x,y) {
# go through each observation and compute the tree-induced weight
tree_weights <- foreach(i=seq_along(x)) %do% {
(x[i]==x)/y
}
# stack tree weights into a matrix
sapply(tree_weights, function(x) as.matrix(x))
},
leaf_IDs, leaf_size, SIMPLIFY=FALSE)
)
tree_weights
tree_weights[[1]]
tree_weights[[2]]
tree_weights[[500]]
forest_weights <- mapply(function(x,y) {
# go through each observation and compute the tree-induced weight
tree_weights <- foreach(i=seq_along(x)) %do% {
(x[i]==x)/y
}
# stack tree weights into a matrix
sapply(tree_weights, function(x) as.matrix(x))
},
leaf_IDs, leaf_size, SIMPLIFY=FALSE)
tree_weights
forest_weights
data <- data[1:25,]
# first get terminal nodes, i.e get terminal nodes for each obs and each tree
# run your (new) data through the forest structure and look where your observations end up
leaf_IDs <- predict(forest, data, type = "terminalNodes")$predictions
# put leaf_IDs into a list (one element for one tree)
leaf_IDs <- lapply(seq_along(leaf_IDs[1,]), function(i) leaf_IDs[,i])
### formula for single tree: 1(Xi in L(x))/abs(L(x)) - normalized by the size of the leaf
## pre-requisites: leaf size and leaf ID
# get the leaf size as counts of observations in leaves
leaf_size <- lapply(leaf_IDs, function(x) ave(x, x, FUN=length))
# initialize list for storage
forest_weights <- vector("list", length = length(leaf_IDs)) # empty list
# initialize tree weight matrix (n x n)
tree_weights <- vector("list", length = length(leaf_IDs[[1]])) # empty list
# check each observation
system.time(
forest_weights <- mapply(function(x,y) {
# go through each observation and compute the tree-induced weight
tree_weights <- foreach(i=seq_along(x)) %do% {
(x[i]==x)/y
}
# stack tree weights into a matrix
sapply(tree_weights, function(x) as.matrix(x))
},
leaf_IDs, leaf_size, SIMPLIFY=FALSE)
)
forest_weights
forest_weights[[1]]
devtools::document()
library(devtools)
devtools::document()
devtools::check()
devtools::document()
devtools::check()
library(orf)
# get some example data and parameters
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
load("sim_data.RData") # load generated data from ologit
X <- as.matrix(odata[, 2:16])
X_test <- as.matrix(odata_test[, 2:16])
Y <- as.matrix(odata[, 1])
ntree <- 1000
mtry <- 5
nmin <- 5
honesty <- FALSE
inference <- FALSE
margins <- FALSE
?rrf
RF1 <- rrf(X,Y,ntree,mtry,nmin,honesty,inference)
devtools::document()
library(devtools)
devtools::document()
devtools::document()
library(devtools)
devtools::document()
devtools::check()
library(orf)
?rrf
# get some example data and parameters
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
load("sim_data.RData") # load generated data from ologit
X <- as.matrix(odata[, 2:16])
X_test <- as.matrix(odata_test[, 2:16])
Y <- as.matrix(odata[, 1])
ntree <- 1000
mtry <- 5
nmin <- 5
honesty <- FALSE
inference <- FALSE
margins <- FALSE
RF1 <- rrf(X,Y,ntree,mtry,nmin,honesty,inference)
RF1$trainForest
RF1$forestInfo
RF1$oobPredictions
RF1$oobMSE
RF2 <- rrf(X,Y,ntree,mtry,nmin,TRUE,inference)
RF2$trainForest
RF2$forestInfo
RF2$honestPredictions
RF2$honestMSE
RF1$oobMSE
RF3 <- rrf(X,Y,ntree,mtry,nmin,TRUE,TRUE)
system.time(RF3 <- rrf(X,Y,ntree,mtry,nmin,TRUE,TRUE))
RF3$honestWeights
RF3$honestWeighs
RF3$honestWeights
rowSums(RF3$honestWeights)
RF3$honestPredictions
RF2$honestPredictions
RF3$honestVariance
RF3$honestMSE
# get some example data and parameters
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
load("sim_data.RData") # load generated data from ologit
X <- as.matrix(odata[, 2:16])
X_test <- as.matrix(odata_test[, 2:16])
Y <- as.matrix(odata[, 1])
ntree <- 1000
mtry <- 5
nmin <- 5
honesty <- FALSE
inference <- FALSE
margins <- FALSE
# load needed libraries for the functions
library(ranger)
#library(foreach)
library(Rcpp)
library(ggplot2)
library(gridExtra)
library(xtable)
# load Rcpp functions first
#sourceCpp("tree_weights_rcpp.cpp")
#sourceCpp("pred_tree_weights_rcpp.cpp")
sourceCpp("list_pred_forest_weights_rcpp.cpp")
sourceCpp("list_get_forest_weights_rcpp.cpp")
sourceCpp("get_honest_rcpp.cpp")
sourceCpp("predict_honest_rcpp.cpp")
# load R functions
source("user_functions_forest.R")
source("get_forest_weights.R")
source("predict_forest_weights.R")
source("predict_honest.R")
source("get_honest.R")
source("honest_split.R")
source("get_variance.R")
source("get_orf_variance.R")
source("user_functions_orf.R")
source("orf_eval_functions.R")
source("cpp_predict_forest_weights_for_ME_new.R")
source("orf_margins.R")
source("pred_orf_margins.R")
source("predict_forest_preds_for_ME.R")
source("pred_orf_variance.R")
source("user_functions_mrf.R")
source("mrf_margins.R")
source("get_mrf_variance.R")
source("pred_mrf_variance.R")
source("pred_mrf_margins.R")
source("stars.R")
# try out the function
set.seed(1)
system.time(
RF1 <- random_forest(X, Y, ntree, mtry, honesty, inference)
)
honesty <- TRUE
set.seed(1)
system.time(
RF2 <- random_forest(X, Y, ntree, mtry, honesty, inference)
)
inference <- TRUE
set.seed(1)
system.time(
RF3 <- random_forest(X, Y, ntree, mtry, honesty, inference)
)
RF3$honestWeights
rowSums(RF3$honestWeights)
nmin <- 10
# try out the function
set.seed(1)
system.time(
RF1 <- random_forest(X, Y, ntree, mtry, honesty, inference)
)
rowSums(RF3$honestWeights)
library("orf", lib.loc="~/R/x86_64-pc-linux-gnu-library/3.5")
# get some example data and parameters
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
load("sim_data.RData") # load generated data from ologit
X <- as.matrix(odata[, 2:16])
X_test <- as.matrix(odata_test[, 2:16])
Y <- as.matrix(odata[, 1])
ntree <- 1000
mtry <- 5
nmin <- 5
honesty <- FALSE
inference <- FALSE
margins <- FALSE
rrf(X,Y,ntree,mtry,nmin,honesty,inference)
RF <- rrf(X,Y,ntree,mtry,nmin,TRUE,TRUE)
rowSums(RF$honestWeights)
RF <- rrf(X,Y,ntree,mtry,10,TRUE,TRUE)
rowSums(RF$honestWeights)
RF <- rrf(X,Y,ntree,mtry,20,TRUE,TRUE)
rowSums(RF$honestWeights)
RF <- rrf(X,Y,ntree,mtry,30,TRUE,TRUE)
rowSums(RF$honestWeights)
RF <- rrf(X,Y,ntree,mtry,50,TRUE,TRUE)
rowSums(RF$honestWeights)
RF <- rrf(X,Y,ntree,mtry,100,TRUE,TRUE)
rowSums(RF$honestWeights)
RF <- rrf(X,Y,10,mtry,100,TRUE,TRUE)
rowSums(RF$honestWeights)
dim(RF$honestWeights)
library(devtools)
devtools::document()
devtools::check()
devtools::document()
devtools::check()
devtools::document()
devtools::check()
devtools::document()
devtools::check()
devtools::document()
devtools::check()
devtools::document()
devtools::check()
devtools::document()
devtools::check()
devtools::document()
devtools::check()
devtools::document()
devtools::check()
library(orf)
?orf
?rrf
?predict.rrf
?plot.rrf
?summary.rrf
######################################################################
#          FUNCTIONS FOR STANDARD RANDOM FOREST : TESTING OUT        #
######################################################################
# get some example data and parameters
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
load("sim_data.RData") # load generated data from ologit
X <- as.matrix(odata[, 2:16])
X_test <- as.matrix(odata_test[, 2:16])
Y <- as.matrix(odata[, 1])
ntree <- 1000
mtry <- 5
nmin <- 5
honesty <- FALSE
inference <- FALSE
margins <- FALSE
# try out the function
set.seed(1)
rrf(X, Y, ntree, mtry, nmin, honesty, inference)
RF <- rrf(X, Y, ntree, mtry, nmin, honesty, inference)
RF?pred <- predict(RF, new_data = X_test)
typeof(RF)
class(RF)
attributes(RF)
library(devtools)
devtools::document()
devtools::check()
library(orf)
# get some example data and parameters
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
load("sim_data.RData") # load generated data from ologit
X <- as.matrix(odata[, 2:16])
X_test <- as.matrix(odata_test[, 2:16])
Y <- as.matrix(odata[, 1])
ntree <- 1000
mtry <- 5
nmin <- 5
honesty <- FALSE
inference <- FALSE
margins <- FALSE
RF <- rrf(X, Y, ntree, mtry, nmin, honesty, inference)
predict(RF, new_data = X_test)
RF_pred <- predict(RF, new_data = X_test)
RF_pred$forestInfo
RF_pred$forestPredictions
View(odata)
head(odata)
summary(RF)
summary(RF, latex = TRUE)
summary(RF, latex = FALSE)
plot(RF)
