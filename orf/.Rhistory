forest_multi_demeaned_sq_sum_scaled_norm <- lapply(forest_multi_demeaned_sq_sum_scaled, function(x) lapply(x, function(x) x*(n_honest/(n_honest-1)) ))
# put it into a shorter named object
variance <- forest_multi_demeaned_sq_sum_scaled_norm
forest_multi_demeaned_sq
forest_multi_demeaned_sq_sum
# put it into a shorter named object
variance <- forest_multi_demeaned_sq_sum_scaled_norm
variance
variance[[1]][[1]]
variance[[1]][[2]]
variance[[1]][[3]]
variance[[1]][[4]]
variance[[1]][[5]]
variance[[1]][[6]]
variance[[1]][[7]]
variance[[1]][[8]]
variance[[1]][[9]]
round(variance[[1]][[9]],5)
round(variance[[1]][[9]],4)
scaling_factor_squared
## now compute the covariances
# multiply forest_var_multi_demeaned according to formula for covariance (shifted categories needed for computational convenience)
forest_multi_demeaned_0_last <- append(forest_multi_demeaned, list(rep(list(matrix(0, ncol = ncol(forest_multi_demeaned[[1]][[1]]), nrow = nrow(forest_multi_demeaned[[1]][[1]]))), ncol(X_honest)))) # append zero matrix list
forest_multi_demeaned_0_first <- append(list(rep(list(matrix(0, ncol = ncol(forest_multi_demeaned[[1]][[1]]), nrow = nrow(forest_multi_demeaned[[1]][[1]]))), ncol(X_honest))), forest_multi_demeaned) # prepend zero matrix list
# compute the multiplication of category m with m-1 according to the covariance formula
forest_multi_demeaned_cov <- mapply(function(x,y) mapply(function(x,y) x*y, x, y, SIMPLIFY = FALSE), forest_multi_demeaned_0_first, forest_multi_demeaned_0_last, SIMPLIFY = F)
# sum all obs i together
forest_multi_demeaned_cov_sum <- lapply(forest_multi_demeaned_cov, function(x) lapply(x, function(x) sum(x)))
# divide by scaling factor
forest_multi_demeaned_cov_sum_scaled <- lapply(forest_multi_demeaned_cov_sum, function(x) mapply(function(x,y) x/y, x, scaling_factor_squared, SIMPLIFY = FALSE) )
# multiply by N/N-1 (normalize)
forest_multi_demeaned_cov_sum_scaled_norm <- lapply(forest_multi_demeaned_cov_sum_scaled, function(x) lapply(x, function(x) x*(n_honest/(n_honest-1)) ))
# multiply by 2
forest_multi_demeaned_cov_sum_scaled_norm_mult2 <- lapply(forest_multi_demeaned_cov_sum_scaled_norm, function(x) lapply(x, function(x) x*2 ))
# put it into a shorter named object
covariance <- forest_multi_demeaned_cov_sum_scaled_norm_mult2
covariance
covariance[[2]]
## put everything together according to the whole variance formula
# shift variances accordingly for ease of next computations (covariance already has the desired format)
variance_last <- append(variance, list(rep(list(0), ncol(X_honest)))) # append zero element list
variance_first <- append(list(rep(list(0), ncol(X_honest))), variance) # prepend zero element list
# put everything together according to formula: var_last + var_first - cov
variance_marginal_effects_final <- mapply(function(x,y,z) mapply(function(x,y,z) x+y-z, x, y, z, SIMPLIFY = FALSE), variance_last, variance_first, covariance, SIMPLIFY = F)
## output for final variances of marginal effects
# coerce to a matrix
variance_marginal_effects <- sapply(variance_marginal_effects_final, function(x) sapply(x, function(x) as.matrix(x)))
# add names
colnames(variance_marginal_effects) <- sapply(cat_honest, function(x) paste("Category", x, sep = " "))
rownames(variance_marginal_effects) <- colnames(X_honest)
## standard deviations
# take square root of variance
sd_marginal_effects <- sqrt(variance_marginal_effects)
#### z scores and p values ####
z_scores <- (marginal_effects)/(sd_marginal_effects)
p_values <- 2*pnorm(-abs(z_scores))
p_values
sd_marginal_effects
round(p_values, 3)
sd_marginal_effects
variance_marginal_effects
round(variance_marginal_effects,5)
round(variance_marginal_effects,6)
######################################################################
#          FUNCTIONS FOR STANDARD RANDOM FOREST : TESTING OUT        #
######################################################################
# get some example data and parameters
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# load needed libraries for the functions
library(ranger)
#library(foreach)
library(Rcpp)
library(ggplot2)
library(gridExtra)
library(xtable)
# load Rcpp functions first
#sourceCpp("tree_weights_rcpp.cpp")
#sourceCpp("pred_tree_weights_rcpp.cpp")
sourceCpp("list_pred_forest_weights_rcpp.cpp")
sourceCpp("list_get_forest_weights_rcpp.cpp")
sourceCpp("get_honest_rcpp.cpp")
sourceCpp("predict_honest_rcpp.cpp")
# load R functions
source("user_functions_forest.R")
source("get_forest_weights.R")
source("predict_forest_weights.R")
source("predict_honest.R")
source("get_honest.R")
source("honest_split.R")
source("get_variance.R")
source("get_orf_variance.R")
source("user_functions_orf.R")
source("orf_eval_functions.R")
source("cpp_predict_forest_weights_for_ME_new.R")
source("orf_margins.R")
source("pred_orf_margins.R")
source("predict_forest_preds_for_ME.R")
source("pred_orf_variance.R")
source("user_functions_mrf.R")
source("mrf_margins.R")
source("get_mrf_variance.R")
source("pred_mrf_variance.R")
source("pred_mrf_margins.R")
source("stars.R")
# load libraries
library(dplyr)
library(ggplot2)
library(grf)
library(boot)
library(ranger)
library(foreach)
# load and prepare data
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
load("~/Documents/HSG/ORF/gauss_comparison/data/orf_sim_data.Rdata")
# load needed functions
source("cpp_predict_forest_weights_for_ME_new.R")
# prepare data as needed
depvar <- "Yo"
ntree <- 1000
mtry <- 5
inference <- TRUE
honesty <- TRUE
eval <- "median"
data <- gauss
# load needed libraries
library(ranger)
# set needed local variables
outcome <- as.data.frame(data[,depvar])
colnames(outcome) <- depvar
X <- data[,which(colnames(data)!=depvar)]
# parameters
n <- as.numeric(nrow(outcome)) # number of observations
cat <- as.numeric(sort(unique(outcome[,1]))) # sequence of categories
ncat <- as.numeric(length(cat)) # number of categories
cat_needed <- cat[1:(ncat-1)] #without the last category (not needed cuz P(Y_ind<=last_cat)=1)
# create indicator variables (outcomes)
Y_ind <- lapply(cat_needed, function(x) ifelse((outcome <= x), 1, 0))
# create dataset
data <- lapply(Y_ind, function(x) as.data.frame(cbind(as.matrix(unlist(x)), X)))
# estimate ncat-1 forests (everything on the same data: placing splits and effect estimation), no subsampling
forest <- lapply(data, function(x) ranger(dependent.variable.name = paste(depvar), data = x, num.trees = ntree, mtry = mtry, replace = TRUE, importance = "none"))
## values for eval
## values for evaluation of the marginal effect - based on honest sample
# share of SD to be used
h_std <- 1
X_honest
X_honest <- X
# check if X is continuous or dummy or categorical
X_type <- apply(X_honest, 2, function(x) length(unique(x)))
# now determine the type of X
X_continuous <- which(X_type > 10) # define IDs of continuous Xs
X_dummy <- which(X_type == 2) # define IDs of dummies
X_categorical <- which(X_type > 2 & X_type <= 10)
# additional check for constant variables which are nonsensical
if (any(X_type == 1) | any(X_type == 0)) {
stop("Some of the covariates are constant. This is non-sensical for evaluation of marginal effects. Programme terminated.")
}
# decide if the marginal effects should be computed at mean or at median
if (eval=="mean") {
# variable of interest: X_1 to X_last, ME at mean
X_mean <- lapply(1:ncol(X_honest), function(x) colMeans(X_honest)) # set all Xs to their mean values (so many times as we have Xs)
} else if (eval=="median") {
# variable of interest: X_1 to X_last, ME at median
X_mean <- lapply(1:ncol(X_honest), function(x) apply(X_honest, 2, median)) # set all Xs to their median values (so many times as we have Xs)
} else {
stop("Incorrect evaluation point. Programme terminated.")
}
# get SD of Xs
X_sd <- apply(X_honest, 2, sd)
# create X_up (X_mean + 0.1 * X_sd)
X_up <- X_mean[[1]] + h_std*X_sd
# create X_down (X_mean - 0.1 * X_sd)
X_down <- X_mean[[1]] - h_std*X_sd
## now check for the support of X
# check X_max
X_max <- apply(X_honest, 2, max)
# check X_min
X_min <- apply(X_honest, 2, min)
# check if X_up is within the range X_min and X_max
X_up <- (X_up < X_max) * X_up + (X_up >= X_max) * X_max
X_up <- (X_up > X_min) * X_up + (X_up <= X_min) * (X_min + h_std * X_sd)
# check if X_down is within the range X_min and X_max
X_down <- (X_down > X_min) * X_down + (X_down <= X_min) * X_min
X_down <- (X_down < X_max) * X_down + (X_down >= X_max) * (X_max - h_std * X_sd)
## now we need 2 datasets: one with X_up and second with X_down
# X_mean_up
X_mean_up <- lapply(seq_along(X_mean), function(i) replace(X_mean[[i]], i, X_up[i]) )
# X_mean_down
X_mean_down <- lapply(seq_along(X_mean), function(i) replace(X_mean[[i]], i, X_down[i]) )
# adjust for categorical X (works also for zero categorical)
for (i in X_categorical) {
X_mean_up[[i]][[i]] <- ceiling(mean(X_honest[,i]))
X_mean_down[[i]][[i]] <- floor(mean(X_honest[,i]))
}
# adjust for dummies (works also for zero dummies)
for (i in X_dummy) {
X_mean_up[[i]][[i]] <- max(X_honest[,i])
X_mean_down[[i]][[i]] <- min(X_honest[,i])
}
# extract weights for desired Xs up: get weights from honest sample and predict weights for evaluation points from HONEST sample
forest_weights_up <- predict_forest_weights_for_ME(forest, X_honest, X_mean_up)
# extract weights for desired Xs down
forest_weights_down <- predict_forest_weights_for_ME(forest, X_honest, X_mean_down)
# now subtract the weights according to the ME formula
forest_weights_diff_up_down <- mapply(function(x,y) mapply(function(x,y) x-y, x, y,  SIMPLIFY = F), forest_weights_up, forest_weights_down, SIMPLIFY = F)
forest_weights_diff_up_down[[1]][[1]]
sum(forest_weights_diff_up_down[[1]][[1]])
forest_weights_up[[1]][[1]]
sum(forest_weights_up[[1]][[1]])
## compute prerequisities for marginal effects
# compute the conditional means: weights%*%y (predictions are based on honest sample)
forest_cond_means <- mapply(function(x,y) lapply(x, function(x) x%*%y), forest_weights_diff_up_down, Y_ind_honest, SIMPLIFY = FALSE)
Y_ind
Y_ind_honest <- Z_ind
Y_ind_honest <- Y_ind
## compute prerequisities for marginal effects
# compute the conditional means: weights%*%y (predictions are based on honest sample)
forest_cond_means <- mapply(function(x,y) lapply(x, function(x) x%*%y), forest_weights_diff_up_down, Y_ind_honest, SIMPLIFY = FALSE)
# subtract conditional means according to formula to isolate categories
forest_cond_means_0_last <- append(forest_cond_means, list(rep(list(0), ncol(X_honest)))) # append zero elemnt list
forest_cond_means_0_first <- append(list(rep(list(0), ncol(X_honest))), forest_cond_means) # prepend zero element list
# compute the scaling factor: X_up-X_down=2*X_sd
scaling_factor <- as.list(X_up - X_down)
scaling_factor
forest_cond_means
forest_cond_means[[1]][[1]]
# now compute the differences for marginal effects
marginal_effects_diff <- mapply(function(x,y) mapply(function(x,y) x-y, x, y, SIMPLIFY = F), forest_cond_means_0_last, forest_cond_means_0_first, SIMPLIFY = F)
# scale marginal effects
marginal_effects_scaled <- lapply(marginal_effects_diff, function(x) mapply(function(x,y) x/y, x, scaling_factor, SIMPLIFY = FALSE) )
## output for final marginal effects
# coerce to a matrix
marginal_effects <- sapply(marginal_effects_scaled, function(x) sapply(x, function(x) as.matrix(x)))
# add names
colnames(marginal_effects) <- sapply(cat_honest, function(x) paste("Category", x, sep = " "))
rownames(marginal_effects) <- colnames(X_honest)
marginal_effects
forest_cond_means[[1]][[1]]
### variance for the marginal effects
## compute prerequisities for variance of honest marginal effects
# scaling factor squared
scaling_factor_squared <- lapply(scaling_factor, function(x) x^2)
scaling_factor_squared
## compute the conditional means (predictions): already have this as forest_cond_means
# divide it by N to get the "mean"
forest_cond_means_mean <- lapply(forest_cond_means, function(x) lapply(x, function(x) x/n_honest))
n_honest <- 1000
## compute the conditional means (predictions): already have this as forest_cond_means
# divide it by N to get the "mean"
forest_cond_means_mean <- lapply(forest_cond_means, function(x) lapply(x, function(x) x/n_honest))
forest_cond_means_mean
forest_cond_means_mean[[1]][[1]]
# calculate standard multiplication of weights and outcomes: honest_weights*y_ind_honest
forest_multi <- mapply(function(x,y) lapply(x, function(x) t(x)*y), forest_weights_diff_up_down, Y_ind_honest, SIMPLIFY = FALSE)
# subtract the mean from each obs i
forest_multi_demeaned <- mapply(function(x,y) mapply(function(x,y) x-matrix(y, nrow = nrow(x)), x, y, SIMPLIFY = FALSE), forest_multi, forest_cond_means_mean, SIMPLIFY = F)
## now do the single variances for each category m
# square the demeaned
forest_multi_demeaned_sq <- lapply(forest_multi_demeaned, function(x) lapply(x, function(x) x^2))
# sum all obs i together
forest_multi_demeaned_sq_sum <- lapply(forest_multi_demeaned_sq, function(x) lapply(x, function(x) sum(x)))
forest_multi_demeaned_sq_sum
forest_multi_demeaned_sq_sum[[1]]
forest_multi_demeaned_sq_sum[[1]][[1]]
# divide by scaling factor
forest_multi_demeaned_sq_sum_scaled <- lapply(forest_multi_demeaned_sq_sum, function(x) mapply(function(x,y) x/y, x, scaling_factor_squared, SIMPLIFY = FALSE) )
# multiply by N/N-1 (normalize)
forest_multi_demeaned_sq_sum_scaled_norm <- lapply(forest_multi_demeaned_sq_sum_scaled, function(x) lapply(x, function(x) x*(n_honest/(n_honest-1)) ))
# put it into a shorter named object
variance <- forest_multi_demeaned_sq_sum_scaled_norm
variance[[1]]
variance[[1]][[1]]
## now compute the covariances
# multiply forest_var_multi_demeaned according to formula for covariance (shifted categories needed for computational convenience)
forest_multi_demeaned_0_last <- append(forest_multi_demeaned, list(rep(list(matrix(0, ncol = ncol(forest_multi_demeaned[[1]][[1]]), nrow = nrow(forest_multi_demeaned[[1]][[1]]))), ncol(X_honest)))) # append zero matrix list
forest_multi_demeaned_0_first <- append(list(rep(list(matrix(0, ncol = ncol(forest_multi_demeaned[[1]][[1]]), nrow = nrow(forest_multi_demeaned[[1]][[1]]))), ncol(X_honest))), forest_multi_demeaned) # prepend zero matrix list
# compute the multiplication of category m with m-1 according to the covariance formula
forest_multi_demeaned_cov <- mapply(function(x,y) mapply(function(x,y) x*y, x, y, SIMPLIFY = FALSE), forest_multi_demeaned_0_first, forest_multi_demeaned_0_last, SIMPLIFY = F)
# sum all obs i together
forest_multi_demeaned_cov_sum <- lapply(forest_multi_demeaned_cov, function(x) lapply(x, function(x) sum(x)))
# divide by scaling factor
forest_multi_demeaned_cov_sum_scaled <- lapply(forest_multi_demeaned_cov_sum, function(x) mapply(function(x,y) x/y, x, scaling_factor_squared, SIMPLIFY = FALSE) )
# multiply by N/N-1 (normalize)
forest_multi_demeaned_cov_sum_scaled_norm <- lapply(forest_multi_demeaned_cov_sum_scaled, function(x) lapply(x, function(x) x*(n_honest/(n_honest-1)) ))
# multiply by 2
forest_multi_demeaned_cov_sum_scaled_norm_mult2 <- lapply(forest_multi_demeaned_cov_sum_scaled_norm, function(x) lapply(x, function(x) x*2 ))
# put it into a shorter named object
covariance <- forest_multi_demeaned_cov_sum_scaled_norm_mult2
covariance[[1]][[1]]
covariance[[2]][[1]]
## put everything together according to the whole variance formula
# shift variances accordingly for ease of next computations (covariance already has the desired format)
variance_last <- append(variance, list(rep(list(0), ncol(X_honest)))) # append zero element list
variance_first <- append(list(rep(list(0), ncol(X_honest))), variance) # prepend zero element list
# put everything together according to formula: var_last + var_first - cov
variance_marginal_effects_final <- mapply(function(x,y,z) mapply(function(x,y,z) x+y-z, x, y, z, SIMPLIFY = FALSE), variance_last, variance_first, covariance, SIMPLIFY = F)
## output for final variances of marginal effects
# coerce to a matrix
variance_marginal_effects <- sapply(variance_marginal_effects_final, function(x) sapply(x, function(x) as.matrix(x)))
# add names
colnames(variance_marginal_effects) <- sapply(cat_honest, function(x) paste("Category", x, sep = " "))
rownames(variance_marginal_effects) <- colnames(X_honest)
variance_marginal_effects
round(variance_marginal_effects)
round(variance_marginal_effects, 4)
round(variance_marginal_effects, 5)
round(variance_marginal_effects, 6)
## standard deviations
# take square root of variance
sd_marginal_effects <- sqrt(variance_marginal_effects)
#### z scores and p values ####
z_scores <- (marginal_effects)/(sd_marginal_effects)
p_values <- 2*pnorm(-abs(z_scores))
p_values
round(p_values, 5)
forest_cond_means[[1]][[1]]
forest_cond_means_0_last
forest_cond_means_0_first
X_mean_up
X_mean
X_mean_up[[1]][[1]]
X_mean_dwon[[1]][[1]]
X_mean_down[[1]][[1]]
X_mean_down[[1]]
forest_cond_means
forest_cond_means[[1]]
forest_cond_means[[1]][[1]]
Y_ind_honest
Y_ind_honest
Y_ind_honest[[1]]
head(Y_ind_honest[[1]])
forest_weights_diff_up_down[[1]]
forest_weights_diff_up_down[[1]][[1]]
forest_weights_diff_up_down[[1]][[1]][1:10]
round(forest_weights_diff_up_down[[1]][[1]][1:10], 8)
forest_weights_diff_up_down[[1]][[1]][1:10]
sum(forest_weights_diff_up_down[[1]][[1]])
marginal_effects
forest_cond_means
forest_cond_means[[1]][[1]]
forest_weights_diff_up_down
forest_weights_diff_up_down[[1]][[1]]
forest_weights_diff_up_down[[1]][[1]][1:10]
round(forest_weights_diff_up_down[[1]][[1]][1:10],8)
forest_cond_means[[1]][[1]]
forest_cond_means_mean
forest_cond_means_mean[[1]][[1]]
forest_multi[[1]][[1]]
head(forest_multi[[1]][[1]])
head(forest_demeaned[[1]][[1]])
head(forest_multi_demeaned[[1]][[1]])
head(forest_multi[[1]][[1]])
forest_cond_means_mean[[1]][[1]]
head(forest_multi_demeaned[[1]][[1]])
scaling_factor_squared
scaling_factor_squared[[1]]
1/scaling_factor_squared[[1]]
variance[[1]]
variance[[1]][[1]]
head(forest_multi_demeaned[[1]][[1]])
round(head(forest_multi_demeaned[[1]][[1]]),5)
round(head(forest_multi_demeaned_sq[[1]][[1]]),5)
round(head(forest_multi_demeaned_sq[[1]][[1]]),9)
round(head(forest_multi_demeaned_sq[[1]][[1]]),8)
round(head(forest_multi_demeaned_sq[[1]][[1]]),7)
round(head(forest_multi_demeaned_sq[[1]][[1]]),6)
head(forest_multi_demeaned_sq[[1]][[1]])
7.094366e-08
7.094366e-08
7.094366*0.00000001
forest_multi_demeaned_sq_sum
forest_multi_demeaned_sq_sum[[1]]
forest_multi_demeaned_sq_sum[[1]][[1]]
forest_multi_demeaned_sq_sum_scaled[[1]][[1]]
forest_multi_demeaned_sq_sum_scaled_norm[[1]][[1]]
marginal_effects
variance_marginal_effects
round(variance_marginal_effects,6)
z_scores
p_values
round(p_values,8)
View(predict_forest_preds_for_ME)
View(predict_forest_weights)
View(coefstars)
library(orf)
?orf
# load needed libraries for the functions
library(ranger)
#library(foreach)
library(Rcpp)
library(ggplot2)
library(gridExtra)
library(xtable)
# load Rcpp functions first
#sourceCpp("tree_weights_rcp
library(grf)
library(orf)
?orf
library(orf)
?orf
?coefstars
?rps
library(devtools)
devtools::use_rcpp()
usethis::use_rcpp()
devtools::document()
library(orf)
?orf
devtools::use_rcpp()
devtools::document()
getLoadedDLLs()
devtools::document()
load_all()
pkgload::load_all()
roxygen2::roxygenize()
pkgbuild::compile_dll()
devtools::document()
pkgbuild::compile_dll()
devtools::document()
pkgbuild::compile_dll()
devtools::document()
pkgbuild::compile_dll()
devtools::document()
library(orf)
devtools::use_rcpp()
devtools::document()
install_version("roxygen2", "6.1.0")
library(devtools)
devtools::use_rcpp()
devtools::document()
install_version("roxygen2", "6.1.1")
`pkgload::load_all()
)
a
a
s`
pkgload::load_all()
library(orf)
devtools::document()
?orf
?grf
library(grf)
?grf
# get some example data and parameters
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
load("sim_data.RData") # load generated data from ologit
X <- as.matrix(odata[, 2:16])
X_test <- as.matrix(odata_test[, 2:16])
Y <- as.matrix(odata[, 1])
ntree <- 1000
mtry <- 5
honesty <- FALSE
inference <- FALSE
margins <- FALSE
# load needed libraries for the functions
library(ranger)
rangerforest <- ranger(Yo ~. , data = odata)
grfforest <- regression_forest(X,Y)
grfforest <- regression_forest(X,Y)
library(grf)
X
Y
Y <- as.numeric(Y)
grfforest <- regression_forest(X,Y)
predict(rangerforest, type = "terminalNodes")
predict(rangerforest, data = odata,type = "terminalNodes")
predict(grfforest, data = odata,type = "terminalNodes")
predict(grfforest, data = odata)
?predict.regression_forest
get_tree(grfforest,1)
tree1 <- get_tree(grfforest,1)
tree1$num_samples
tree1$drawn_samples
tree1$nodes
sort(tree1$drawn_samples)
tree1$nodes
unlist(tree1$nodes)
unlist(tree1$nodes)
sort(unlist(tree1$nodes))
unique(sort(unlist(tree1$nodes)))
grfforest <- regression_forest(X,Y, honesty = TRUE, honesty.fraction = 0.9)
tree1 <- get_tree(grfforest,1)
tree1$nodes
sort(unlist(tree1$nodes))
unique(sort(unlist(tree1$nodes)))
library(devtools)
devtools::load_all()
devtools::document()
usethis::use_package("ranger")
devtools::document()
devtools::use_rcpp()
devtools::document()
getLoadedDLLs()
pkgbuild::compile_dll()
devtools::document()
devtools::session_info("devtools")
pkgbuild::compile_dll()
pkgbuild::compile_dll()
devtools::document()
devtools::check()
devtools::load_all()
devtools::document()
install_version("roxygen2", "6.0.1")
library(roxygen2)
library(devtools)
library("roxygen2", lib.loc="~/R/x86_64-pc-linux-gnu-library/3.5")
use_rcpp()
devtools::document()
devtools::check()
devtools::check()
install.packages("roxygen2")
install.packages("roxygen2")
